{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Issue Generator\n",
    "\n",
    "Use this notebook to create synthetic data quality issues for the ingestion DAG demo. It produces a base dataset, then introduces at least seven issue types the DAG can detect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DATA = Path('../Data/raw_dataset.csv')\n",
    "OUTPUT_DIR = Path('../Data/raw')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "assert BASE_DATA.exists(), f'Base dataset missing: {BASE_DATA}'\n",
    "base_df = pd.read_csv(BASE_DATA)\n",
    "base_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue recipes\n",
    "We introduce at least seven errors:\n",
    "1. **missing_column**: drop a required feature.\n",
    "2. **missing_value**: insert NaNs into required fields.\n",
    "3. **unknown_category**: set Geography/Gender to unexpected values.\n",
    "4. **out_of_bounds**: push numeric values outside allowed ranges.\n",
    "5. **non_numeric**: place strings in numeric columns.\n",
    "6. **invalid_boolean**: use non-binary values for `HasCrCard` / `IsActiveMember`.\n",
    "7. **duplicate_row**: duplicate existing records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_COLUMNS = [\n",
    "    'RowNumber','CustomerId','Surname','CreditScore','Geography','Gender','Age',\n",
    "    'Tenure','Balance','NumOfProducts','HasCrCard','IsActiveMember','EstimatedSalary'\n",
    "]\n",
    "\n",
    "def make_copy(df, name, mutator):\n",
    "    mutated = mutator(df.copy(deep=True))\n",
    "    path = OUTPUT_DIR / f'{name}.csv'\n",
    "    mutated.to_csv(path, index=False)\n",
    "    print(f'Wrote {path} ({len(mutated)} rows)')\n",
    "\n",
    "make_copy(base_df, 'missing_column', lambda d: d.drop(columns=['Balance']))\n",
    "\n",
    "make_copy(base_df, 'missing_value', lambda d: d.assign(CreditScore=np.where(d.index % 5 == 0, np.nan, d.CreditScore)))\n",
    "\n",
    "make_copy(base_df, 'unknown_category', lambda d: d.assign(Geography=np.where(d.index % 7 == 0, 'Atlantis', d.Geography)))\n",
    "\n",
    "make_copy(base_df, 'out_of_bounds', lambda d: d.assign(Age=np.where(d.index % 4 == 0, 999, d.Age)))\n",
    "\n",
    "make_copy(base_df, 'non_numeric', lambda d: d.assign(Tenure=np.where(d.index % 6 == 0, 'ten', d.Tenure)))\n",
    "\n",
    "make_copy(base_df, 'invalid_boolean', lambda d: d.assign(HasCrCard=np.where(d.index % 3 == 0, 2, d.HasCrCard)))\n",
    "\n",
    "def add_duplicates(df):\n",
    "    dupes = df.head(10)\n",
    "    return pd.concat([df, dupes], ignore_index=True)\n",
    "make_copy(base_df, 'duplicate_row', add_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell above to refresh the synthetic error files, then trigger the ingestion DAG to validate them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
